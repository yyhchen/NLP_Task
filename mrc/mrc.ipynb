{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95de447-998e-40b4-af00-451087008400",
   "metadata": {},
   "source": [
    "# åŸºäºæˆªæ–­ç­–ç•¥çš„æœºå™¨é˜…è¯»ç†è§£ä»»åŠ¡å®æˆ˜Â Â "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241f13f-76c1-4094-a06b-9d9ee50b3586",
   "metadata": {},
   "source": [
    "## å¯¼å…¥ç›¸å…³åŒ…Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â \n",
    "ç”±äºåšçš„æ˜¯ç±»ä¼¼ **é—®ç­”ä»»åŠ¡** æ•…é‡‡ç”¨ `AutoModelForQuestionAnswering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbdd9bb3-fdaf-4344-82c3-04d1ac70f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, DefaultDataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf09e3-a151-4ebb-8f2b-81d9297aab2e",
   "metadata": {},
   "source": [
    "## æ•°æ®åŠ è½½Â Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac1be4c-e18e-4f3b-a626-356345385c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 10142\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 3219\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 1002\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset(\"cmrc2018\", cache_dir=\"data\", trust_remote_code=True)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc982582-36ef-46c8-a603-c23e80915fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TRAIN_186_QUERY_0',\n",
       " 'context': 'èŒƒå»·é¢‚æ¢æœºï¼ˆï¼Œï¼‰ï¼Œåœ£åä¿ç¦„Â·è‹¥ç‘Ÿï¼ˆï¼‰ï¼Œæ˜¯è¶Šå—ç½—é©¬å¤©ä¸»æ•™æ¢æœºã€‚1963å¹´è¢«ä»»ä¸ºä¸»æ•™ï¼›1990å¹´è¢«æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†ï¼›1994å¹´è¢«æ“¢å‡ä¸ºæ€»ä¸»æ•™ï¼ŒåŒå¹´å¹´åº•è¢«æ“¢å‡ä¸ºæ¢æœºï¼›2009å¹´2æœˆç¦»ä¸–ã€‚èŒƒå»·é¢‚äº1919å¹´6æœˆ15æ—¥åœ¨è¶Šå—å®å¹³çœå¤©ä¸»æ•™å‘è‰³æ•™åŒºå‡ºç”Ÿï¼›ç«¥å¹´æ—¶æ¥å—è‰¯å¥½æ•™è‚²åï¼Œè¢«ä¸€ä½è¶Šå—ç¥çˆ¶å¸¦åˆ°æ²³å†…ç»§ç»­å…¶å­¦ä¸šã€‚èŒƒå»·é¢‚äº1940å¹´åœ¨æ²³å†…å¤§ä¿®é“é™¢å®Œæˆç¥å­¦å­¦ä¸šã€‚èŒƒå»·é¢‚äº1949å¹´6æœˆ6æ—¥åœ¨æ²³å†…çš„ä¸»æ•™åº§å ‚æ™‹é“ï¼›åŠåè¢«æ´¾åˆ°åœ£å¥³å°å¾·å…°å­¤å„¿é™¢æœåŠ¡ã€‚1950å¹´ä»£ï¼ŒèŒƒå»·é¢‚åœ¨æ²³å†…å ‚åŒºåˆ›å»ºç§»æ°‘æ¥å¾…ä¸­å¿ƒä»¥æ”¶å®¹åˆ°æ²³å†…é¿æˆ˜çš„éš¾æ°‘ã€‚1954å¹´ï¼Œæ³•è¶Šæˆ˜äº‰ç»“æŸï¼Œè¶Šå—æ°‘ä¸»å…±å’Œå›½å»ºéƒ½æ²³å†…ï¼Œå½“æ—¶å¾ˆå¤šå¤©ä¸»æ•™ç¥èŒäººå‘˜é€ƒè‡³è¶Šå—çš„å—æ–¹ï¼Œä½†èŒƒå»·é¢‚ä»ç„¶ç•™åœ¨æ²³å†…ã€‚ç¿Œå¹´ç®¡ç†åœ£è‹¥æœ›å°ä¿®é™¢ï¼›æƒŸåœ¨1960å¹´å› æå«ä¿®é™¢çš„è‡ªç”±ã€è‡ªæ²»åŠæ‹’ç»æ”¿åºœåœ¨ä¿®é™¢è®¾æ”¿æ²»è¯¾çš„è¦æ±‚è€Œè¢«æ•ã€‚1963å¹´4æœˆ5æ—¥ï¼Œæ•™å®—ä»»å‘½èŒƒå»·é¢‚ä¸ºå¤©ä¸»æ•™åŒ—å®æ•™åŒºä¸»æ•™ï¼ŒåŒå¹´8æœˆ15æ—¥å°±ä»»ï¼›å…¶ç‰§é“­ä¸ºã€Œæˆ‘ä¿¡å¤©ä¸»çš„çˆ±ã€ã€‚ç”±äºèŒƒå»·é¢‚è¢«è¶Šå—æ”¿åºœè½¯ç¦å·®ä¸å¤š30å¹´ï¼Œå› æ­¤ä»–æ— æ³•åˆ°æ‰€å±å ‚åŒºè¿›è¡Œç‰§çµå·¥ä½œè€Œä¸“æ³¨ç ”è¯»ç­‰å·¥ä½œã€‚èŒƒå»·é¢‚é™¤äº†é¢å¯¹æˆ˜äº‰ã€è´«å›°ã€è¢«å½“å±€è¿«å®³å¤©ä¸»æ•™ä¼šç­‰é—®é¢˜å¤–ï¼Œä¹Ÿç§˜å¯†æ¢å¤ä¿®é™¢ã€åˆ›å»ºå¥³ä¿®ä¼šå›¢ä½“ç­‰ã€‚1990å¹´ï¼Œæ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–åœ¨åŒå¹´6æœˆ18æ—¥æ“¢å‡èŒƒå»·é¢‚ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†ä»¥å¡«è¡¥è¯¥æ•™åŒºæ€»ä¸»æ•™çš„ç©ºç¼ºã€‚1994å¹´3æœˆ23æ—¥ï¼ŒèŒƒå»·é¢‚è¢«æ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™å¹¶å…¼å¤©ä¸»æ•™è°…å±±æ•™åŒºå®—åº§ç½²ç†ï¼›åŒå¹´11æœˆ26æ—¥ï¼Œè‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡èŒƒå»·é¢‚ä¸ºæ¢æœºã€‚èŒƒå»·é¢‚åœ¨1995å¹´è‡³2001å¹´æœŸé—´å‡ºä»»å¤©ä¸»æ•™è¶Šå—ä¸»æ•™å›¢ä¸»å¸­ã€‚2003å¹´4æœˆ26æ—¥ï¼Œæ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–ä»»å‘½å¤©ä¸»æ•™è°…å±±æ•™åŒºå…¼å¤©ä¸»æ•™é«˜å¹³æ•™åŒºå´å…‰æ°ä¸»æ•™ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºç½²ç†ä¸»æ•™ï¼›åŠè‡³2005å¹´2æœˆ19æ—¥ï¼ŒèŒƒå»·é¢‚å› è·æ‰¹è¾å»æ€»ä¸»æ•™èŒåŠ¡è€Œè£ä¼‘ï¼›å´å…‰æ°åŒæ—¥çœŸé™¤å¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™èŒåŠ¡ã€‚èŒƒå»·é¢‚äº2009å¹´2æœˆ22æ—¥æ¸…æ™¨åœ¨æ²³å†…ç¦»ä¸–ï¼Œäº«å¹´89å²ï¼›å…¶è‘¬ç¤¼äºåŒæœˆ26æ—¥ä¸Šåˆåœ¨å¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™åº§å ‚ä¸¾è¡Œã€‚',\n",
       " 'question': 'èŒƒå»·é¢‚æ˜¯ä»€ä¹ˆæ—¶å€™è¢«ä»»ä¸ºä¸»æ•™çš„ï¼Ÿ',\n",
       " 'answers': {'text': ['1963å¹´'], 'answer_start': [30]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27932f-4d48-4d4a-a854-0f139ac12f68",
   "metadata": {},
   "source": [
    "## æ•°æ®é¢„å¤„ç†Â Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881166f0-704d-4a06-9ddb-2104a8108d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f57dd1-5c00-4748-a9f6-aacdb4cb126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = datasets[\"train\"].select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cb527-28ff-4463-8023-1b386d867acb",
   "metadata": {},
   "source": [
    "### tokenizerä¸­çš„å‚æ•°è§£é‡Š\n",
    "1. `text`: è¿™ä¸ªå‚æ•°ç”¨äºä¼ é€’è¦åˆ†è¯çš„ä¸»è¦æ–‡æœ¬ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå®ƒæ¥è‡ªäº`sample_dataset[\"question\"]`ï¼Œè¿™é€šå¸¸æ„å‘³ç€å®ƒæ˜¯é—®é¢˜æ–‡æœ¬ã€‚\n",
    "2. `text_pair`: è¿™ä¸ªå‚æ•°ç”¨äºä¼ é€’ä¸ä¸»è¦æ–‡æœ¬é…å¯¹çš„ç¬¬äºŒæ®µæ–‡æœ¬ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå®ƒæ¥è‡ªäº`sample_dataset[\"context\"]`ï¼Œè¿™é€šå¸¸æ„å‘³ç€å®ƒæ˜¯ä¸é—®é¢˜ç›¸å…³çš„ä¸Šä¸‹æ–‡æ–‡æœ¬ã€‚åœ¨æŸäº›ä»»åŠ¡ä¸­ï¼Œæ¯”å¦‚é—®ç­”ä»»åŠ¡ï¼Œæ¨¡å‹çš„è¾“å…¥é€šå¸¸åŒ…æ‹¬é—®é¢˜å’Œå…¶ä¸Šä¸‹æ–‡ã€‚\n",
    "3. `return_offsets_mapping`: è¿™ä¸ªå‚æ•°è®¾ç½®ä¸º`True`ï¼Œæ„å‘³ç€åˆ†è¯å™¨å°†è¿”å›æ¯ä¸ªåˆ†è¯ä¸å…¶åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„ä½ç½®æ˜ å°„ã€‚è¿™å¯¹äºåç»­çš„ä»»åŠ¡ï¼Œæ¯”å¦‚è§£é‡Šæ¨¡å‹é¢„æµ‹æˆ–é”™è¯¯åˆ†æï¼Œæ˜¯éå¸¸æœ‰ç”¨çš„ã€‚\n",
    "4. `max_length`: è¿™ä¸ªå‚æ•°æŒ‡å®šäº†åˆ†è¯å™¨è¾“å‡ºçš„åºåˆ—çš„æœ€å¤§é•¿åº¦ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæœ€å¤§é•¿åº¦è¢«è®¾ç½®ä¸º512ä¸ªä»¤ç‰Œï¼ˆtokenï¼‰ã€‚å¦‚æœè¾“å…¥æ–‡æœ¬çš„é•¿åº¦è¶…è¿‡è¿™ä¸ªå€¼ï¼Œæ–‡æœ¬å°†è¢«æˆªæ–­ã€‚\n",
    "5. `truncation`: è¿™ä¸ªå‚æ•°æŒ‡å®šäº†å¦‚ä½•å¤„ç†è¶…å‡º`max_length`çš„æ–‡æœ¬ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`truncation=\"only_second\"` æ„å‘³ç€åªæœ‰ç¬¬äºŒæ®µæ–‡æœ¬ï¼ˆå³`text_pair`ï¼‰ä¼šè¢«æˆªæ–­ï¼Œè€Œä¸»è¦æ–‡æœ¬ï¼ˆ`text`ï¼‰ä¸ä¼šè¢«æˆªæ–­ã€‚\n",
    "\n",
    "\n",
    "æ¯”å¦‚ `return_offsets_mapping = True`ä¸­ï¼Œå‡è®¾å¥å­ä¸ºï¼šHello, how are you?Â  å¾—åˆ°çš„ç»“æœå¯èƒ½å¦‚ä¸‹ï¼š\n",
    "tokens: ['Hello', ',', 'how', 'are', 'you', '?']\n",
    "offset_mapping: [(0, 5), (5, 6), (7, 10), (11, 14), (15, 18), (18, 19)]\n",
    "  Â Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5fcde2-e842-4984-9bc7-a88106a20818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples = tokenizer(text=sample_dataset[\"question\"],\n",
    "                               text_pair=sample_dataset[\"context\"],\n",
    "                               return_offsets_mapping=True,\n",
    "                               max_length=512, truncation=\"only_second\", padding=\"max_length\")\n",
    "tokenized_examples.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e623e66-20fb-4835-86fe-4596692f17e1",
   "metadata": {},
   "source": [
    "### å¯ä»¥çœ‹åˆ°æœ‰ä¸¤ä¸ª offset_mappingÂ Â Â Â Â \n",
    "ç¬¬äºŒè¡Œç¬¬ä¸‰ä¸ªå°±æ˜¯ç¬¬äºŒæ®µæ–‡æœ¬çš„ (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4636c38-b097-4ac4-bd5f-f501b71a1f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 62), (62, 63), (63, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 105), (105, 106), (106, 107), (107, 108), (108, 110), (110, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 153), (153, 154), (154, 155), (155, 156), (156, 157), (157, 158), (158, 159), (159, 163), (163, 164), (164, 165), (165, 166), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (179, 180), (180, 181), (181, 182), (182, 186), (186, 187), (187, 188), (188, 189), (189, 190), (190, 191), (191, 192), (192, 193), (193, 194), (194, 195), (195, 196), (196, 197), (197, 198), (198, 199), (199, 200), (200, 201), (201, 202), (202, 203), (203, 204), (204, 205), (205, 206), (206, 207), (207, 208), (208, 209), (209, 210), (210, 211), (211, 212), (212, 213), (213, 214), (214, 215), (215, 216), (216, 217), (217, 218), (218, 222), (222, 223), (223, 224), (224, 225), (225, 226), (226, 227), (227, 228), (228, 229), (229, 230), (230, 231), (231, 232), (232, 233), (233, 234), (234, 235), (235, 236), (236, 237), (237, 238), (238, 239), (239, 240), (240, 241), (241, 242), (242, 243), (243, 244), (244, 245), (245, 246), (246, 247), (247, 248), (248, 249), (249, 250), (250, 251), (251, 252), (252, 253), (253, 257), (257, 258), (258, 259), (259, 260), (260, 261), (261, 262), (262, 263), (263, 264), (264, 265), (265, 266), (266, 267), (267, 268), (268, 269), (269, 270), (270, 271), (271, 272), (272, 273), (273, 274), (274, 275), (275, 276), (276, 277), (277, 278), (278, 279), (279, 280), (280, 281), (281, 282), (282, 283), (283, 284), (284, 285), (285, 286), (286, 287), (287, 288), (288, 289), (289, 290), (290, 291), (291, 292), (292, 293), (293, 294), (294, 295), (295, 296), (296, 297), (297, 298), (298, 299), (299, 300), (300, 301), (301, 302), (302, 303), (303, 304), (304, 305), (305, 306), (306, 307), (307, 308), (308, 309), (309, 310), (310, 311), (311, 312), (312, 313), (313, 314), (314, 315), (315, 316), (316, 317), (317, 318), (318, 319), (319, 320), (320, 321), (321, 325), (325, 326), (326, 327), (327, 328), (328, 329), (329, 330), (330, 331), (331, 332), (332, 333), (333, 334), (334, 335), (335, 336), (336, 337), (337, 338), (338, 339), (339, 340), (340, 341), (341, 342), (342, 343), (343, 344), (344, 345), (345, 346), (346, 347), (347, 348), (348, 349), (349, 350), (350, 351), (351, 352), (352, 353), (353, 354), (354, 355), (355, 356), (356, 360), (360, 361), (361, 362), (362, 363), (363, 364), (364, 365), (365, 366), (366, 367), (367, 368), (368, 369), (369, 370), (370, 371), (371, 372), (372, 373), (373, 374), (374, 375), (375, 376), (376, 377), (377, 378), (378, 379), (379, 380), (380, 381), (381, 382), (382, 383), (383, 384), (384, 385), (385, 386), (386, 387), (387, 388), (388, 390), (390, 391), (391, 392), (392, 393), (393, 394), (394, 395), (395, 396), (396, 397), (397, 398), (398, 399), (399, 400), (400, 401), (401, 402), (402, 403), (403, 404), (404, 405), (405, 406), (406, 407), (407, 408), (408, 409), (409, 410), (410, 411), (411, 412), (412, 413), (413, 414), (414, 415), (415, 416), (416, 417), (417, 418), (418, 419), (419, 420), (420, 421), (421, 422), (422, 424), (424, 425), (425, 426), (426, 427), (427, 428), (428, 429), (429, 430), (430, 431), (431, 432), (432, 433), (433, 434), (434, 435), (435, 436), (436, 437), (437, 438), (438, 439), (439, 440), (440, 441), (441, 442), (442, 443), (443, 444), (444, 445), (445, 446), (446, 447), (447, 448), (448, 449), (449, 450), (450, 451), (451, 452), (452, 453), (453, 454), (454, 455), (455, 456), (456, 457), (457, 458), (458, 459), (459, 460), (460, 461), (461, 462), (462, 463), (463, 464), (464, 465), (465, 466), (466, 467), (467, 468), (468, 469), (469, 470), (470, 471), (471, 472), (472, 473), (473, 474), (474, 475), (475, 476), (476, 477), (477, 478), (478, 479), (479, 480), (480, 481), (481, 482), (482, 483), (483, 484), (484, 485), (485, 486), (486, 487), (487, 488), (488, 489), (489, 490), (490, 491), (491, 492), (492, 493), (493, 494), (494, 495), (495, 499), (499, 500), (500, 501), (501, 502), (502, 503), (503, 504), (504, 505), (505, 506), (506, 507), (507, 508), (508, 509), (509, 510), (510, 511), (511, 512), (512, 513), (513, 514), (514, 516), (516, 517), (517, 518), (518, 519), (519, 520), (520, 521), (521, 522), (522, 523), (523, 524), (524, 525), (525, 526), (526, 527), (527, 528), (528, 529), (529, 530), (530, 531), (531, 532), (532, 533), (533, 534), (0, 0)] --- 512\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_examples[\"offset_mapping\"][0], \"---\", len(tokenized_examples[\"offset_mapping\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1ee537-9a32-44cb-822d-402b3ef08865",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_mapping = tokenized_examples.pop(\"offset_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fa682e-65ab-4107-a236-f16efbd51876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(offset_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec1d8a0-a400-449d-97b0-5f923115805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = tokenized_examples.sequence_ids(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfea8ca-39ce-4f97-9e67-2c9a7581aa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "print(temp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580048a0-7731-44bb-a1c4-98b77625a233",
   "metadata": {},
   "source": [
    "### è°ƒè¯• answers èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®(å­—ç¬¦)Â Â Â Â Â \n",
    "è¿™é‡Œæ‹¿åˆ°çš„ä»…ä»…åªæ˜¯å­—ç¬¦çš„ä½ç½®ï¼Œåç»­è¿˜éœ€è¦æ‹¿åˆ°tokençš„ä½ç½®æ‰æ˜¯æˆ‘ä»¬æƒ³è¦çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6c26cc-0b25-49da-af3e-afdd9fbda205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['1963å¹´'], 'answer_start': [30]} 30 35\n",
      "{'text': ['1990å¹´è¢«æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†'], 'answer_start': [41]} 41 62\n",
      "{'text': ['èŒƒå»·é¢‚äº1919å¹´6æœˆ15æ—¥åœ¨è¶Šå—å®å¹³çœå¤©ä¸»æ•™å‘è‰³æ•™åŒºå‡ºç”Ÿ'], 'answer_start': [97]} 97 126\n",
      "{'text': ['1994å¹´3æœˆ23æ—¥ï¼ŒèŒƒå»·é¢‚è¢«æ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™å¹¶å…¼å¤©ä¸»æ•™è°…å±±æ•™åŒºå®—åº§ç½²ç†'], 'answer_start': [548]} 548 598\n",
      "{'text': ['èŒƒå»·é¢‚äº2009å¹´2æœˆ22æ—¥æ¸…æ™¨åœ¨æ²³å†…ç¦»ä¸–'], 'answer_start': [759]} 759 780\n",
      "{'text': ['ã€Šå…¨ç¾è¶…çº§æ¨¡ç‰¹å„¿æ–°ç§€å¤§èµ›ã€‹ç¬¬åå­£'], 'answer_start': [26]} 26 42\n",
      "{'text': ['æœ‰å‰é€”çš„æ–°é¢å­”'], 'answer_start': [247]} 247 254\n",
      "{'text': ['ã€ŠJetã€‹ã€ã€Šä¸œæ–¹æ—¥æŠ¥ã€‹ã€ã€ŠElleã€‹ç­‰'], 'answer_start': [706]} 706 726\n",
      "{'text': ['å”®è´§å‘˜'], 'answer_start': [202]} 202 205\n",
      "{'text': ['å¤§ç©ºç¿¼'], 'answer_start': [84]} 84 87\n"
     ]
    }
   ],
   "source": [
    "for idx, offset in enumerate(offset_mapping):\n",
    "    answer = sample_dataset[idx]['answers']\n",
    "    start_char = answer['answer_start'][0]\n",
    "    end_char = start_char + len(answer['text'][0])\n",
    "    print(answer, start_char, end_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d8459-1d4e-4094-bccd-7388bf06d6cd",
   "metadata": {},
   "source": [
    "### ä»£ç è§£é‡ŠÂ Â Â Â Â \n",
    "é¦–å…ˆï¼Œ`tokenized_examples.sequence_ids(idx)`è¿”å›çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«äº†å½“å‰æ ·æœ¬ï¼ˆç”±ç´¢å¼•`idx`æŒ‡å®šï¼‰åœ¨åˆ†è¯åçš„åºåˆ—ä¸­çš„æ¯ä¸ªä»¤ç‰Œçš„ç±»å‹ã€‚è¿™ä¸ªåˆ—è¡¨é€šå¸¸åŒ…å«ä¸‰ä¸ªå¯èƒ½çš„å€¼ï¼š\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- `0`ï¼šè¡¨ç¤ºè¯¥ä»¤ç‰Œæ¥è‡ª`question`æ–‡æœ¬ã€‚Â Â Â Â Â \n",
    "- `1`ï¼šè¡¨ç¤ºè¯¥ä»¤ç‰Œæ¥è‡ª`context`æ–‡æœ¬ã€‚Â Â Â Â Â \n",
    "- `None`ï¼šè¡¨ç¤ºè¯¥ä»¤ç‰Œæ˜¯ç‰¹æ®Šä»¤ç‰Œï¼Œå¦‚åˆ†éš”ç¬¦æˆ–å¡«å……ç¬¦ã€‚Â Â Â Â Â \n",
    "ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåˆ†è¯åçš„åºåˆ—ï¼Œå…¶`sequence_ids`å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼šÂ Â Â Â Â \n",
    "```\n",
    "[0, 0, 0, 0, None, 1, 1, 1, 1, 1, None, None, None]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå‰å››ä¸ªä»¤ç‰Œæ¥è‡ªé—®é¢˜æ–‡æœ¬ï¼Œç„¶åæ˜¯ä¸€ä¸ªç‰¹æ®Šä»¤ç‰Œï¼ˆå¦‚åˆ†éš”ç¬¦ï¼‰ï¼Œæ¥ä¸‹æ¥çš„äº”ä¸ªä»¤ç‰Œæ¥è‡ªä¸Šä¸‹æ–‡æ–‡æœ¬ï¼Œæœ€åæ˜¯ä¸‰ä¸ªå¡«å……ä»¤ç‰Œã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬è§£é‡Šè¿™ä¸¤å¥ä»£ç ï¼šÂ Â Â Â Â \n",
    "1. `context_start = tokenized_examples.sequence_ids(idx).index(1)`ï¼šè¿™è¡Œä»£ç æŸ¥æ‰¾`sequence_ids`åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªå€¼ä¸º`1`çš„ä»¤ç‰Œçš„ä½ç½®ã€‚è¿™ä¸ªä½ç½®æ ‡å¿—ç€`context`æ–‡æœ¬åœ¨åˆ†è¯ååºåˆ—ä¸­çš„å¼€å§‹ã€‚åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œ`context_start`å°†æ˜¯5ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. `context_end = tokenized_examples.sequence_ids(idx).index(None, context_start) - 1`ï¼šè¿™è¡Œä»£ç ä»`context_start`å¼€å§‹æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå€¼ä¸º`None`çš„ä»¤ç‰Œçš„ä½ç½®ï¼Œç„¶åå‡å»1ï¼Œå¾—åˆ°`context`æ–‡æœ¬åœ¨åˆ†è¯ååºåˆ—ä¸­çš„ç»“æŸä½ç½®ã€‚åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œ`context_end`å°†æ˜¯9ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "è‡³äº`if`åˆ¤æ–­ä¸­çš„`offset`ï¼Œå®ƒæ¥è‡ªäºä¹‹å‰æåˆ°çš„`offset_mapping`ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±åˆ†è¯å™¨è¿”å›çš„åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«äº†æ¯ä¸ªåˆ†è¯åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„èµ·å§‹å’Œç»“æŸä½ç½®ã€‚åœ¨`if`åˆ¤æ–­ä¸­ï¼Œ`offset`ç”¨äºæ¯”è¾ƒç­”æ¡ˆçš„å­—ç¬¦ä½ç½®å’Œ`context`æ–‡æœ¬çš„å­—ç¬¦ä½ç½®ï¼Œä»¥ç¡®å®šç­”æ¡ˆæ˜¯å¦åœ¨`context`æ–‡æœ¬ä¸­ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa8c01f-2d81-47ba-b16f-23cdc0f192e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['1963å¹´'], 'answer_start': [30]} 30 35 17 510 47 48\n",
      "token answer decode: 1963 å¹´\n",
      "{'text': ['1990å¹´è¢«æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºå®—åº§ç½²ç†'], 'answer_start': [41]} 41 62 15 510 53 70\n",
      "token answer decode: 1990 å¹´ è¢« æ“¢ å‡ ä¸º å¤© ä¸» æ•™ æ²³ å†… æ€» æ•™ åŒº å®— åº§ ç½² ç†\n",
      "{'text': ['èŒƒå»·é¢‚äº1919å¹´6æœˆ15æ—¥åœ¨è¶Šå—å®å¹³çœå¤©ä¸»æ•™å‘è‰³æ•™åŒºå‡ºç”Ÿ'], 'answer_start': [97]} 97 126 15 510 100 124\n",
      "token answer decode: èŒƒ å»· é¢‚ äº 1919 å¹´ 6 æœˆ 15 æ—¥ åœ¨ è¶Š å— å® å¹³ çœ å¤© ä¸» æ•™ å‘ è‰³ æ•™ åŒº å‡º ç”Ÿ\n",
      "{'text': ['1994å¹´3æœˆ23æ—¥ï¼ŒèŒƒå»·é¢‚è¢«æ•™å®—è‹¥æœ›ä¿ç¦„äºŒä¸–æ“¢å‡ä¸ºå¤©ä¸»æ•™æ²³å†…æ€»æ•™åŒºæ€»ä¸»æ•™å¹¶å…¼å¤©ä¸»æ•™è°…å±±æ•™åŒºå®—åº§ç½²ç†'], 'answer_start': [548]} 548 598 17 510 0 0\n",
      "token answer decode: [CLS]\n",
      "{'text': ['èŒƒå»·é¢‚äº2009å¹´2æœˆ22æ—¥æ¸…æ™¨åœ¨æ²³å†…ç¦»ä¸–'], 'answer_start': [759]} 759 780 12 510 0 0\n",
      "token answer decode: [CLS]\n",
      "{'text': ['ã€Šå…¨ç¾è¶…çº§æ¨¡ç‰¹å„¿æ–°ç§€å¤§èµ›ã€‹ç¬¬åå­£'], 'answer_start': [26]} 26 42 21 510 47 62\n",
      "token answer decode: ã€Š å…¨ ç¾ è¶… çº§ æ¨¡ ç‰¹ å„¿ æ–° ç§€ å¤§ èµ› ã€‹ ç¬¬ å å­£\n",
      "{'text': ['æœ‰å‰é€”çš„æ–°é¢å­”'], 'answer_start': [247]} 247 254 20 510 232 238\n",
      "token answer decode: æœ‰ å‰ é€” çš„ æ–° é¢ å­”\n",
      "{'text': ['ã€ŠJetã€‹ã€ã€Šä¸œæ–¹æ—¥æŠ¥ã€‹ã€ã€ŠElleã€‹ç­‰'], 'answer_start': [706]} 706 726 20 510 0 0\n",
      "token answer decode: [CLS]\n",
      "{'text': ['å”®è´§å‘˜'], 'answer_start': [202]} 202 205 18 510 205 207\n",
      "token answer decode: å”® è´§ å‘˜\n",
      "{'text': ['å¤§ç©ºç¿¼'], 'answer_start': [84]} 84 87 21 486 105 107\n",
      "token answer decode: å¤§ ç©º ç¿¼\n"
     ]
    }
   ],
   "source": [
    "for idx, offset in enumerate(offset_mapping):\n",
    "    answer = sample_dataset[idx][\"answers\"]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = start_char + len(answer[\"text\"][0])\n",
    "    # å®šä½ç­”æ¡ˆåœ¨tokenä¸­çš„èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®Â Â \n",
    "    # ä¸€ç§ç­–ç•¥ï¼Œæˆ‘ä»¬è¦æ‹¿åˆ°contextçš„èµ·å§‹å’Œç»“æŸï¼Œç„¶åä»å·¦å³ä¸¤ä¾§å‘ç­”æ¡ˆé€¼è¿‘Â Â \n",
    "\n",
    "    context_start = tokenized_examples.sequence_ids(idx).index(1)\n",
    "    context_end = tokenized_examples.sequence_ids(idx).index(None, context_start) - 1\n",
    "\n",
    "    # åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦åœ¨contextä¸­\n",
    "    if offset[context_end][1] < start_char or offset[context_start][0] > end_char:\n",
    "        start_token_pos = 0\n",
    "        end_token_pos = 0\n",
    "    else:\n",
    "        token_id = context_start\n",
    "        while token_id <= context_end and offset[token_id][0] < start_char:\n",
    "            token_id += 1\n",
    "        start_token_pos = token_id\n",
    "        token_id = context_end\n",
    "        while token_id >= context_start and offset[token_id][1] > end_char:\n",
    "            token_id -=1\n",
    "        end_token_pos = token_id\n",
    "        \n",
    "    print(answer, start_char, end_char, context_start, context_end, start_token_pos, end_token_pos)\n",
    "    print(\"token answer decode:\", tokenizer.decode(tokenized_examples[\"input_ids\"][idx][start_token_pos: end_token_pos + 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9f089-ef71-48b8-91f7-8d55f57ae093",
   "metadata": {},
   "source": [
    "## å°†ä¸Šé¢è°ƒè¯•å¥½çš„ä»£ç è¿›è¡Œå°è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57ae3773-3808-42e9-8258-2864affdfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    tokenized_examples = tokenizer(text=examples[\"question\"],\n",
    "                               text_pair=examples[\"context\"],\n",
    "                               return_offsets_mapping=True,\n",
    "                               max_length=384, truncation=\"only_second\", padding=\"max_length\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for idx, offset in enumerate(offset_mapping):\n",
    "        answer = examples[\"answers\"][idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answer[\"text\"][0])\n",
    "        # å®šä½ç­”æ¡ˆåœ¨tokenä¸­çš„èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®\n",
    "        # ä¸€ç§ç­–ç•¥ï¼Œæˆ‘ä»¬è¦æ‹¿åˆ°contextçš„èµ·å§‹å’Œç»“æŸï¼Œç„¶åä»å·¦å³ä¸¤ä¾§å‘ç­”æ¡ˆé€¼è¿‘\n",
    "        context_start = tokenized_examples.sequence_ids(idx).index(1)\n",
    "        context_end = tokenized_examples.sequence_ids(idx).index(None, context_start) - 1\n",
    "        # åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦åœ¨contextä¸­\n",
    "        if offset[context_end][1] < start_char or offset[context_start][0] > end_char:\n",
    "            start_token_pos = 0\n",
    "            end_token_pos = 0\n",
    "        else:\n",
    "            token_id = context_start\n",
    "            while token_id <= context_end and offset[token_id][0] < start_char:\n",
    "                token_id += 1\n",
    "            start_token_pos = token_id\n",
    "            token_id = context_end\n",
    "            while token_id >= context_start and offset[token_id][1] > end_char:\n",
    "                token_id -=1\n",
    "            end_token_pos = token_id\n",
    "        start_positions.append(start_token_pos)\n",
    "        end_positions.append(end_token_pos)\n",
    "    \n",
    "    tokenized_examples[\"start_positions\"] = start_positions\n",
    "    tokenized_examples[\"end_positions\"] = end_positions\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11bc9d4c-20d5-4724-8d1b-7b65d53443f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a622f4962bb94755ac66ed0f55267ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 10142\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 3219\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 1002\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenied_datasets = datasets.map(process_func, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "\n",
    "tokenied_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385785a9-db35-44ba-9956-7de111601800",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ model loading Â Â Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7150ee9a-2954-493c-8d28-430643fcf801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\anaconda3\\envs\\transformers\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"hfl/chinese-macbert-base\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f4644-407b-4f8a-8df2-db40c47907ed",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ é…ç½® TrainingArgumentsÂ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f6e0a9-c61b-4ca7-b1ed-fd9fe873de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\anaconda3\\envs\\transformers\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"models_for_mrc\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e78d924d-2dac-4f8c-bd38-8853a5433f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(output_dir=\"models_for_mrc\",      # è¾“å‡ºæ–‡ä»¶å¤¹\n",
    "                               per_device_train_batch_size=1,   # è®­ç»ƒæ—¶çš„batch_size\n",
    "                               gradient_accumulation_steps=32,  # *** æ¢¯åº¦ç´¯åŠ  ***\n",
    "                               gradient_checkpointing=True,     # *** æ¢¯åº¦æ£€æŸ¥ç‚¹ ***\n",
    "                               optim=\"adafactor\",               # *** adafactorä¼˜åŒ–å™¨ *** \n",
    "                               per_device_eval_batch_size=1,    # éªŒè¯æ—¶çš„batch_size\n",
    "                               num_train_epochs=1,              # è®­ç»ƒè½®æ•°\n",
    "                               logging_steps=10,                # log æ‰“å°çš„é¢‘ç‡\n",
    "                               eval_strategy=\"epoch\",     # è¯„ä¼°ç­–ç•¥\n",
    "                               save_strategy=\"epoch\",           # ä¿å­˜ç­–ç•¥\n",
    "                               save_total_limit=3,              # æœ€å¤§ä¿å­˜æ•°\n",
    "                               learning_rate=2e-5,              # å­¦ä¹ ç‡\n",
    "                               weight_decay=0.01,               # weight_decay\n",
    "                               metric_for_best_model=\"f1\",      # è®¾å®šè¯„ä¼°æŒ‡æ ‡\n",
    "                               load_best_model_at_end=True)     # è®­ç»ƒå®ŒæˆååŠ è½½æœ€ä¼˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9705e-a3a1-4048-bc60-902ac7d1ee0d",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£Â é…ç½®TrainerÂ Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b757386d-6372-4360-88d0-0a4bf038cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenied_datasets[\"train\"],\n",
    "    eval_dataset=tokenied_datasets[\"validation\"],\n",
    "    data_collator=DefaultDataCollator()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38c219-45c3-43f9-9041-3e582942caa9",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ model trainingÂ Â Â \n",
    "3070 8G è®­ç»ƒäº† 1ä¸ªå°æ—¶9åˆ†é’Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3056c7f9-2926-4643-861f-f382a093aacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='317' max='317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [317/317 1:09:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.382400</td>\n",
       "      <td>1.101883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=317, training_loss=1.7628894589300788, metrics={'train_runtime': 4181.6163, 'train_samples_per_second': 2.425, 'train_steps_per_second': 0.076, 'total_flos': 1987553780112384.0, 'train_loss': 1.7628894589300788, 'epoch': 1.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83942a5-67cc-45bd-a5da-1da813679b26",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ model predictionÂ Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb385593-c2dd-4454-90f4-5c8e462f99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70390347-0f32-432f-971b-266dd341aaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6652287840843201, 'start': 3, 'end': 5, 'answer': 'åŒ—äº¬'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(question=\"å°æ˜åœ¨å“ªé‡Œä¸Šç­ï¼Ÿ\", context=\"å°æ˜åœ¨åŒ—äº¬ä¸Šç­ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0ed81-cfa2-4c32-8cca-4a10d86128f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
