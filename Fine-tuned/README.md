# Fine-tuned based PEFT

[PEFT æ€»ç»“ç»¼è¿°](https://arxiv.org/abs/2303.15647)

ğŸ“¦ æœ¬ç¯å¢ƒç”¨çš„å…¨æ˜¯åŸºäº `Causal language model`, ä»£ç åŸºäºéƒ½æ˜¯ä¸€æ ·ï¼Œåªæœ‰ `fine-tuned` éƒ¨åˆ†æœ‰åŒºåˆ«

---

<br>
<br>

## BitFit fine-tuned 

### ç®€ä»‹

[bitfit ç®€ä»‹](https://github.com/yyhchen/Notes/blob/main/NLP%20review/fine-tuned/BitFit/BitFit.md)

### å®éªŒæ‹†è§£
1. åŒ…æ‹¬åˆ†ææ¨¡å‹å‚æ•°ç»†èŠ‚åŠå ç”¨æ˜¾å­˜, å¦‚ä½•æ‰‹åŠ¨è®¾ç½®fine-tuned åªæ›´æ–° `bias` éƒ¨åˆ†å‚æ•°
2. å¦‚ä½•æ›´ç»†ç²’åº¦å¾—åªä¿å­˜ `bias` éƒ¨åˆ†çš„å‚æ•°ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ¨¡å‹å‚æ•°ï¼Œå¹¶åšå‡ºäº†ä¿å­˜å‰å å‚æ•°çš„æ¯”è¾ƒéƒ¨åˆ†


<br>
<br>



## Prompt-tuning

### ç®€ä»‹

[prompt-tuning ç®€ä»‹](https://github.com/yyhchen/Notes/blob/main/NLP%20review/fine-tuned/Prompt-Tuning/Prompt-tuning.md)


### å®éªŒæ‹†è§£
1. ç”± `prompt-tuning` å¼•å‡º Prompt çš„ä¸¤ç§å½¢å¼ï¼Œ`soft` å’Œ `hard`; `soft prompt` æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œé€šå¸¸æ¥è¯´ `prompt-tuning` çš„ `soft prompt` æ•ˆæœä¼šæ¯”è¾ƒå·®ï¼Œéœ€è¦ç»è¿‡æ›´å¤šçš„ `epoch` æ¥è·å–å¥½çš„ æ•ˆæœã€‚
2. è·Ÿä¹‹å‰çš„ `bitft tuning` ç›¸æ¯”ï¼Œå‚æ•°é‡å¤§å¤§ä¸‹é™ï¼Œä»æ¨¡å‹çš„ä¿¡æ¯å¯ä»¥è·å–å‚æ•°ä¸‹é™çš„åŸå› ã€‚



<br>
<br>


## P-tuning

### ç®€ä»‹

[p-tuning ç®€ä»‹]()

### å®éªŒæ‹†è§£
1. `p-tuning` åœ¨ `prompt-tuning` åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ï¼Œåœ¨ `embedding` å±‚çš„ `prompt` å‰ç¼€åŠ ä¸Šäº†ä¸€ä¸ª é‡å‚æ•°åŒ–çš„è¡Œä¸ºï¼ˆä¸¤ç§ï¼šMLPå’ŒLSTMï¼‰ã€‚



<br>
<br>



## Prefix-tuning

### ç®€ä»‹

[prefix-tuning ç®€ä»‹](https://github.com/yyhchen/Notes/tree/main/NLP%20review/fine-tuned/Prefix-Tuning)

### å®éªŒæ‹†è§£
1. è·Ÿ `p-tuning` å¾ˆåƒï¼Œä½†æ˜¯ `p-tuning` æ˜¯åœ¨embeddingå±‚è¿›è¡Œæ‹¼æ¥ï¼› `prefix-tuning` æ˜¯åœ¨æ•´ä¸ª **transformers blocks** è¿›è¡Œæ‹¼æ¥ç„¶åè¿›è¡Œå­¦ä¹ çš„ã€‚
2. åˆ©ç”¨äº† kv cache çš„åŸç†


<br>
<br>



## LoRA

### ç®€ä»‹

[LoRA ç®€ä»‹](https://github.com/yyhchen/Notes/tree/main/NLP%20review/fine-tuned/LoRA)

### å®éªŒæ‹†è§£
1. åˆ†æäº† `LoRA` å¯ä»¥å¦‚ä½•æ·»åŠ  åœ¨ä¸åŒçš„å‚æ•°å±‚ï¼Œé»˜è®¤åªåœ¨ `query_key_value` å‚æ•°å±‚è¿›è¡Œ åˆ†è§£
2. å¯¹æ¯”äº† åŠ è½½ `LoRA` æ¨¡å‹ å’Œ åˆå¹¶ `LoRA` æ¨¡å—çš„ä¸¤ç§è¡Œä¸º 